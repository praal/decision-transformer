{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18c8c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dm_alchemy import symbolic_alchemy\n",
    "level_name = 'alchemy/perceptual_mapping_randomized_with_rotation_and_random_bottleneck'\n",
    "env = symbolic_alchemy.get_symbolic_alchemy_level(level_name, seed=314)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dd3582e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_spec()['symbolic_obs'].shape\n",
    "env.action_spec().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb10cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: alchemy true\n",
      "1000 trajectories, 200000 timesteps found\n",
      "Average return: 39.82, std: 28.57\n",
      "Max return: 136.00, min: -31.00\n",
      "==================================================\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20221127_044817-19wihhis\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgym-experiment-alchemy-true-748863\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer/runs/19wihhis\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "================================================================================\n",
      "Iteration 1\n",
      "time/training: 275.94120931625366\n",
      "time/total: 277.3568434715271\n",
      "time/evaluation: 0.00022745132446289062\n",
      "training/train_loss_mean: 119.69052359924316\n",
      "training/train_loss_std: 9.005897856301667\n",
      "training/action_error: 105.7898178100586\n",
      "================================================================================\n",
      "Iteration 2\n",
      "time/training: 273.77055406570435\n",
      "time/total: 551.1671946048737\n",
      "time/evaluation: 0.00020503997802734375\n",
      "training/train_loss_mean: 119.4081053161621\n",
      "training/train_loss_std: 8.877603194459066\n",
      "training/action_error: 124.1595230102539\n",
      "================================================================================\n",
      "Iteration 3\n",
      "time/training: 273.5042552947998\n",
      "time/total: 824.6774742603302\n",
      "time/evaluation: 0.0002071857452392578\n",
      "training/train_loss_mean: 119.31279774780273\n",
      "training/train_loss_std: 8.85837847709469\n",
      "training/action_error: 124.62956237792969\n",
      "================================================================================\n",
      "Iteration 4\n",
      "time/training: 273.48568892478943\n",
      "time/total: 1098.1696710586548\n",
      "time/evaluation: 0.0002048015594482422\n",
      "training/train_loss_mean: 119.37996712265014\n",
      "training/train_loss_std: 8.943250785454916\n",
      "training/action_error: 119.69290161132812\n",
      "================================================================================\n",
      "Iteration 5\n",
      "time/training: 273.4514102935791\n",
      "time/total: 1371.6271131038666\n",
      "time/evaluation: 0.0002052783966064453\n",
      "training/train_loss_mean: 119.48385154953003\n",
      "training/train_loss_std: 8.795424510907775\n",
      "training/action_error: 101.38692474365234\n",
      "================================================================================\n",
      "Iteration 6\n",
      "time/training: 273.43681359291077\n",
      "time/total: 1645.0700962543488\n",
      "time/evaluation: 0.00020813941955566406\n",
      "training/train_loss_mean: 119.22847498703003\n",
      "training/train_loss_std: 8.81529063628715\n",
      "training/action_error: 117.19883728027344\n",
      "================================================================================\n",
      "Iteration 7\n",
      "time/training: 273.1463167667389\n",
      "time/total: 1918.2227399349213\n",
      "time/evaluation: 0.00022077560424804688\n",
      "training/train_loss_mean: 119.3263051437378\n",
      "training/train_loss_std: 8.863856385642498\n",
      "training/action_error: 109.31301879882812\n",
      "================================================================================\n",
      "Iteration 8\n",
      "time/training: 273.1924047470093\n",
      "time/total: 2191.4214153289795\n",
      "time/evaluation: 0.0002079010009765625\n",
      "training/train_loss_mean: 119.37157376403809\n",
      "training/train_loss_std: 8.880315119751737\n",
      "training/action_error: 113.19709777832031\n",
      "================================================================================\n",
      "Iteration 9\n",
      "time/training: 273.1778872013092\n",
      "time/total: 2464.6052067279816\n",
      "time/evaluation: 0.0002841949462890625\n",
      "training/train_loss_mean: 119.283289087677\n",
      "training/train_loss_std: 8.90218907564533\n",
      "training/action_error: 108.49143981933594\n",
      "================================================================================\n",
      "Iteration 10\n",
      "time/training: 273.2274839878082\n",
      "time/total: 2737.8387587070465\n",
      "time/evaluation: 0.00020742416381835938\n",
      "training/train_loss_mean: 119.29333478317261\n",
      "training/train_loss_std: 8.97549865807814\n",
      "training/action_error: 134.8216552734375\n",
      "================================================================================\n",
      "Iteration 11\n",
      "time/training: 273.51128029823303\n",
      "time/total: 3011.3560531139374\n",
      "time/evaluation: 0.0002105236053466797\n",
      "training/train_loss_mean: 119.40470402755737\n",
      "training/train_loss_std: 8.911376404926752\n",
      "training/action_error: 110.843505859375\n",
      "================================================================================\n",
      "Iteration 12\n",
      "time/training: 273.44365406036377\n",
      "time/total: 3284.805683851242\n",
      "time/evaluation: 0.00020837783813476562\n",
      "training/train_loss_mean: 119.35723563461303\n",
      "training/train_loss_std: 9.027764577390911\n",
      "training/action_error: 120.98538970947266\n",
      "================================================================================\n",
      "Iteration 13\n",
      "time/training: 273.18677520751953\n",
      "time/total: 3557.998090028763\n",
      "time/evaluation: 0.00020241737365722656\n",
      "training/train_loss_mean: 119.27632458267212\n",
      "training/train_loss_std: 8.902245892106516\n",
      "training/action_error: 123.04183959960938\n",
      "================================================================================\n",
      "Iteration 14\n",
      "time/training: 273.39760279655457\n",
      "time/total: 3831.4015350341797\n",
      "time/evaluation: 0.00021004676818847656\n",
      "training/train_loss_mean: 119.45281071090699\n",
      "training/train_loss_std: 8.75138031391758\n",
      "training/action_error: 113.22644805908203\n",
      "================================================================================\n",
      "Iteration 15\n",
      "time/training: 273.3651165962219\n",
      "time/total: 4104.772660493851\n",
      "time/evaluation: 0.0002067089080810547\n",
      "training/train_loss_mean: 119.39673839035034\n",
      "training/train_loss_std: 8.929878404094197\n",
      "training/action_error: 122.80994415283203\n",
      "================================================================================\n",
      "Iteration 16\n",
      "time/training: 273.30286955833435\n",
      "time/total: 4378.081624507904\n",
      "time/evaluation: 0.00021076202392578125\n",
      "training/train_loss_mean: 119.43816477203369\n",
      "training/train_loss_std: 8.929729997611588\n",
      "training/action_error: 113.20358276367188\n",
      "================================================================================\n",
      "Iteration 17\n",
      "time/training: 273.77983379364014\n",
      "time/total: 4651.872368812561\n",
      "time/evaluation: 0.0002048015594482422\n",
      "training/train_loss_mean: 119.38051787414551\n",
      "training/train_loss_std: 8.81862256135139\n",
      "training/action_error: 116.99325561523438\n",
      "================================================================================\n",
      "Iteration 18\n",
      "time/training: 273.2769658565521\n",
      "time/total: 4925.155294895172\n",
      "time/evaluation: 0.0002079010009765625\n",
      "training/train_loss_mean: 119.27033699645996\n",
      "training/train_loss_std: 8.720441907682954\n",
      "training/action_error: 120.64404296875\n",
      "================================================================================\n",
      "Iteration 19\n",
      "time/training: 273.2987813949585\n",
      "time/total: 5198.460250616074\n",
      "time/evaluation: 0.00020694732666015625\n",
      "training/train_loss_mean: 119.44567161712646\n",
      "training/train_loss_std: 8.900119943698497\n",
      "training/action_error: 128.62510681152344\n",
      "================================================================================\n",
      "Iteration 20\n",
      "time/training: 273.30263686180115\n",
      "time/total: 5471.768994569778\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 119.26786184921265\n",
      "training/train_loss_std: 8.933851805375932\n",
      "training/action_error: 115.32547760009766\n",
      "================================================================================\n",
      "Iteration 21\n",
      "time/training: 273.169296503067\n",
      "time/total: 5744.944457292557\n",
      "time/evaluation: 0.00020599365234375\n",
      "training/train_loss_mean: 119.2314910835266\n",
      "training/train_loss_std: 8.696490446055096\n",
      "training/action_error: 129.93075561523438\n",
      "================================================================================\n",
      "Iteration 22\n",
      "time/training: 273.13269662857056\n",
      "time/total: 6018.114095926285\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 119.43278896942138\n",
      "training/train_loss_std: 8.89375255017101\n",
      "training/action_error: 118.32981872558594\n",
      "================================================================================\n",
      "Iteration 23\n",
      "time/training: 273.2662048339844\n",
      "time/total: 6291.387080669403\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 119.28669035873413\n",
      "training/train_loss_std: 8.833475024962528\n",
      "training/action_error: 121.30833435058594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Iteration 24\n",
      "time/training: 273.2002069950104\n",
      "time/total: 6564.594007730484\n",
      "time/evaluation: 0.00020384788513183594\n",
      "training/train_loss_mean: 119.30275886993408\n",
      "training/train_loss_std: 8.953071296579656\n",
      "training/action_error: 143.914306640625\n",
      "================================================================================\n",
      "Iteration 25\n",
      "time/training: 273.51879358291626\n",
      "time/total: 6838.119071722031\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 119.37802975845337\n",
      "training/train_loss_std: 8.846449599089665\n",
      "training/action_error: 111.38211059570312\n",
      "================================================================================\n",
      "Iteration 26\n",
      "time/training: 273.24695777893066\n",
      "time/total: 7111.372834205627\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 119.432172631073\n",
      "training/train_loss_std: 8.814093702080573\n",
      "training/action_error: 112.4865493774414\n",
      "================================================================================\n",
      "Iteration 27\n",
      "time/training: 273.2428398132324\n",
      "time/total: 7384.622104406357\n",
      "time/evaluation: 0.00020551681518554688\n",
      "training/train_loss_mean: 119.24157391815186\n",
      "training/train_loss_std: 8.867572818190101\n",
      "training/action_error: 119.75314331054688\n",
      "================================================================================\n",
      "Iteration 28\n",
      "time/training: 272.9716908931732\n",
      "time/total: 7657.606232881546\n",
      "time/evaluation: 0.00020766258239746094\n",
      "training/train_loss_mean: 119.30180298614502\n",
      "training/train_loss_std: 8.879898846867965\n",
      "training/action_error: 109.36531829833984\n",
      "================================================================================\n",
      "Iteration 29\n",
      "time/training: 273.37799739837646\n",
      "time/total: 7930.99085521698\n",
      "time/evaluation: 0.0002071857452392578\n",
      "training/train_loss_mean: 119.297367993927\n",
      "training/train_loss_std: 8.912583129778954\n",
      "training/action_error: 124.96508026123047\n",
      "================================================================================\n",
      "Iteration 30\n",
      "time/training: 273.362521648407\n",
      "time/total: 8204.366394281387\n",
      "time/evaluation: 0.00029587745666503906\n",
      "training/train_loss_mean: 119.36068390655518\n",
      "training/train_loss_std: 8.817540432912104\n",
      "training/action_error: 112.78767395019531\n",
      "================================================================================\n",
      "Iteration 31\n",
      "time/training: 273.2686126232147\n",
      "time/total: 8477.647360086441\n",
      "time/evaluation: 0.00020599365234375\n",
      "training/train_loss_mean: 119.37820354919434\n",
      "training/train_loss_std: 8.95408996670009\n",
      "training/action_error: 117.0681381225586\n",
      "================================================================================\n",
      "Iteration 32\n",
      "time/training: 273.17471385002136\n",
      "time/total: 8751.271914720535\n",
      "time/evaluation: 0.0002117156982421875\n",
      "training/train_loss_mean: 119.38326554641723\n",
      "training/train_loss_std: 8.681668581934499\n",
      "training/action_error: 121.38216400146484\n",
      "================================================================================\n",
      "Iteration 33\n",
      "time/training: 273.0594186782837\n",
      "time/total: 9024.337592363358\n",
      "time/evaluation: 0.00020766258239746094\n",
      "training/train_loss_mean: 119.41255820999146\n",
      "training/train_loss_std: 8.76455692333487\n",
      "training/action_error: 122.11177825927734\n",
      "================================================================================\n",
      "Iteration 34\n",
      "time/training: 273.2403795719147\n",
      "time/total: 9297.584025144577\n",
      "time/evaluation: 0.00025844573974609375\n",
      "training/train_loss_mean: 119.49907149353028\n",
      "training/train_loss_std: 8.943331211040004\n",
      "training/action_error: 118.00169372558594\n",
      "================================================================================\n",
      "Iteration 35\n",
      "time/training: 273.27974486351013\n",
      "time/total: 9570.869281053543\n",
      "time/evaluation: 0.00022268295288085938\n",
      "training/train_loss_mean: 119.21668058700561\n",
      "training/train_loss_std: 8.91851281661884\n",
      "training/action_error: 125.4439926147461\n",
      "================================================================================\n",
      "Iteration 36\n",
      "time/training: 273.677481174469\n",
      "time/total: 9844.553416728973\n",
      "time/evaluation: 0.00026226043701171875\n",
      "training/train_loss_mean: 119.27046378860473\n",
      "training/train_loss_std: 8.76048715548383\n",
      "training/action_error: 125.79141998291016\n",
      "================================================================================\n",
      "Iteration 37\n",
      "time/training: 273.51215052604675\n",
      "time/total: 10118.072292089462\n",
      "time/evaluation: 0.00020503997802734375\n",
      "training/train_loss_mean: 119.36145663299561\n",
      "training/train_loss_std: 8.894787978310646\n",
      "training/action_error: 129.807861328125\n",
      "================================================================================\n",
      "Iteration 38\n",
      "time/training: 273.3703191280365\n",
      "time/total: 10391.449185848236\n",
      "time/evaluation: 0.00020575523376464844\n",
      "training/train_loss_mean: 119.33738248977662\n",
      "training/train_loss_std: 8.83012808611853\n",
      "training/action_error: 117.2674331665039\n",
      "================================================================================\n",
      "Iteration 39\n",
      "time/training: 273.1229875087738\n",
      "time/total: 10664.578781604767\n",
      "time/evaluation: 0.00020956993103027344\n",
      "training/train_loss_mean: 119.29225729293823\n",
      "training/train_loss_std: 8.818609140258724\n",
      "training/action_error: 129.06365966796875\n"
     ]
    }
   ],
   "source": [
    "!python experiment.py --env alchemy --dataset true --model_type dt --max_iters 100 -w True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8ab7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: alchemy chem\n",
      "1000 trajectories, 200000 timesteps found\n",
      "Average return: 39.82, std: 28.57\n",
      "Max return: 136.00, min: -31.00\n",
      "==================================================\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20221127_165147-1hr8s5qa\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgym-experiment-alchemy-chem-111325\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer/runs/1hr8s5qa\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "================================================================================\n",
      "Iteration 1\n",
      "time/training: 298.556791305542\n",
      "time/total: 299.9823315143585\n",
      "time/evaluation: 0.00023055076599121094\n",
      "training/train_loss_mean: 119.72875534667969\n",
      "training/train_loss_std: 9.028030620520699\n",
      "training/action_error: 96.86676788330078\n",
      "================================================================================\n",
      "Iteration 2\n",
      "time/training: 328.61086678504944\n",
      "time/total: 628.6330487728119\n",
      "time/evaluation: 0.0002079010009765625\n",
      "training/train_loss_mean: 119.2372945236206\n",
      "training/train_loss_std: 8.91519656662479\n",
      "training/action_error: 117.22750091552734\n",
      "================================================================================\n",
      "Iteration 3\n",
      "time/training: 315.7186076641083\n",
      "time/total: 944.3574321269989\n",
      "time/evaluation: 0.0002079010009765625\n",
      "training/train_loss_mean: 119.3575658996582\n",
      "training/train_loss_std: 8.797687425108474\n",
      "training/action_error: 113.98960876464844\n",
      "================================================================================\n",
      "Iteration 4\n",
      "time/training: 314.31295347213745\n",
      "time/total: 1258.6767721176147\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 119.22710256652832\n",
      "training/train_loss_std: 8.816365759399122\n",
      "training/action_error: 135.10902404785156\n",
      "================================================================================\n",
      "Iteration 5\n",
      "time/training: 320.3012697696686\n",
      "time/total: 1578.9839098453522\n",
      "time/evaluation: 0.00020956993103027344\n",
      "training/train_loss_mean: 119.30876969223023\n",
      "training/train_loss_std: 8.782632602878635\n",
      "training/action_error: 115.49457550048828\n",
      "================================================================================\n",
      "Iteration 6\n",
      "time/training: 309.19151997566223\n",
      "time/total: 1888.1817173957825\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 119.29723582077027\n",
      "training/train_loss_std: 8.87517981671809\n",
      "training/action_error: 118.14795684814453\n",
      "================================================================================\n",
      "Iteration 7\n",
      "time/training: 316.4951767921448\n",
      "time/total: 2204.6824758052826\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 119.41289779586792\n",
      "training/train_loss_std: 8.909170996663347\n",
      "training/action_error: 117.72830200195312\n",
      "================================================================================\n",
      "Iteration 8\n",
      "time/training: 317.90578985214233\n",
      "time/total: 2522.59441781044\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 119.36340624847412\n",
      "training/train_loss_std: 8.816361700686901\n",
      "training/action_error: 124.35261535644531\n",
      "================================================================================\n",
      "Iteration 9\n",
      "time/training: 303.4097719192505\n",
      "time/total: 2826.0105316638947\n",
      "time/evaluation: 0.00021195411682128906\n",
      "training/train_loss_mean: 119.31685919189454\n",
      "training/train_loss_std: 8.871287723520387\n",
      "training/action_error: 120.58747863769531\n",
      "================================================================================\n",
      "Iteration 10\n",
      "time/training: 302.37992238998413\n",
      "time/total: 3128.396422147751\n",
      "time/evaluation: 0.00021266937255859375\n",
      "training/train_loss_mean: 119.37979400634765\n",
      "training/train_loss_std: 8.858114868430995\n",
      "training/action_error: 105.77996063232422\n",
      "================================================================================\n",
      "Iteration 11\n",
      "time/training: 305.9798240661621\n",
      "time/total: 3434.382487297058\n",
      "time/evaluation: 0.00021529197692871094\n",
      "training/train_loss_mean: 119.45210096588134\n",
      "training/train_loss_std: 8.891594123595311\n",
      "training/action_error: 123.81307983398438\n",
      "================================================================================\n",
      "Iteration 12\n",
      "time/training: 313.9445745944977\n",
      "time/total: 3748.3335452079773\n",
      "time/evaluation: 0.00020742416381835938\n",
      "training/train_loss_mean: 119.32228098220826\n",
      "training/train_loss_std: 8.900638956163215\n",
      "training/action_error: 112.82615661621094\n",
      "================================================================================\n",
      "Iteration 13\n",
      "time/training: 313.54917073249817\n",
      "time/total: 4061.8888731002808\n",
      "time/evaluation: 0.00020742416381835938\n",
      "training/train_loss_mean: 119.22390110092164\n",
      "training/train_loss_std: 8.809159732679264\n",
      "training/action_error: 116.4026870727539\n",
      "================================================================================\n",
      "Iteration 14\n",
      "time/training: 320.7568745613098\n",
      "time/total: 4382.651528120041\n",
      "time/evaluation: 0.00020956993103027344\n",
      "training/train_loss_mean: 119.39388234176636\n",
      "training/train_loss_std: 8.771762901104225\n",
      "training/action_error: 114.65503692626953\n",
      "================================================================================\n",
      "Iteration 15\n",
      "time/training: 315.9317593574524\n",
      "time/total: 4698.589643239975\n",
      "time/evaluation: 0.000209808349609375\n",
      "training/train_loss_mean: 119.41967362823486\n",
      "training/train_loss_std: 8.872037706924923\n",
      "training/action_error: 116.08557891845703\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:11.268181, resuming normal operation.\n",
      "================================================================================\n",
      "Iteration 16\n",
      "time/training: 306.4539701938629\n",
      "time/total: 5005.049865961075\n",
      "time/evaluation: 0.00021076202392578125\n",
      "training/train_loss_mean: 119.26752653961182\n",
      "training/train_loss_std: 8.881356855394644\n",
      "training/action_error: 112.20860290527344\n",
      "================================================================================\n",
      "Iteration 17\n",
      "time/training: 306.27747774124146\n",
      "time/total: 5311.333815574646\n",
      "time/evaluation: 0.00020837783813476562\n",
      "training/train_loss_mean: 119.39563820190429\n",
      "training/train_loss_std: 8.999548390179411\n",
      "training/action_error: 122.3777847290039\n",
      "================================================================================\n",
      "Iteration 18\n",
      "time/training: 318.66986203193665\n",
      "time/total: 5630.010126113892\n",
      "time/evaluation: 0.0002079010009765625\n",
      "training/train_loss_mean: 119.38943199005126\n",
      "training/train_loss_std: 8.872420470166173\n",
      "training/action_error: 135.53245544433594\n",
      "================================================================================\n",
      "Iteration 19\n",
      "time/training: 305.12294697761536\n",
      "time/total: 5935.139437913895\n",
      "time/evaluation: 0.0002887248992919922\n",
      "training/train_loss_mean: 119.4136861076355\n",
      "training/train_loss_std: 8.885036619901452\n",
      "training/action_error: 119.26781463623047\n",
      "================================================================================\n",
      "Iteration 20\n",
      "time/training: 310.56028604507446\n",
      "time/total: 6245.7065346241\n",
      "time/evaluation: 0.00020766258239746094\n",
      "training/train_loss_mean: 119.25415138931274\n",
      "training/train_loss_std: 8.821850025301151\n",
      "training/action_error: 119.9490966796875\n",
      "================================================================================\n",
      "Iteration 21\n",
      "time/training: 305.50968837738037\n",
      "time/total: 6551.2226893901825\n",
      "time/evaluation: 0.00020194053649902344\n",
      "training/train_loss_mean: 119.28398848114014\n",
      "training/train_loss_std: 8.933241028406849\n",
      "training/action_error: 121.72111511230469\n",
      "================================================================================\n",
      "Iteration 22\n",
      "time/training: 313.1087658405304\n",
      "time/total: 6864.3707938194275\n",
      "time/evaluation: 0.00020766258239746094\n",
      "training/train_loss_mean: 119.32194709472657\n",
      "training/train_loss_std: 8.886863491169986\n",
      "training/action_error: 108.99920654296875\n",
      "================================================================================\n",
      "Iteration 23\n",
      "time/training: 310.47703528404236\n",
      "time/total: 7174.854098320007\n",
      "time/evaluation: 0.0002048015594482422\n",
      "training/train_loss_mean: 119.41871200714111\n",
      "training/train_loss_std: 8.872253203441213\n",
      "training/action_error: 115.40874481201172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Iteration 24\n",
      "time/training: 312.92281579971313\n",
      "time/total: 7487.782769680023\n",
      "time/evaluation: 0.00020813941955566406\n",
      "training/train_loss_mean: 119.2304831352234\n",
      "training/train_loss_std: 8.866936432358592\n",
      "training/action_error: 117.4188003540039\n",
      "================================================================================\n",
      "Iteration 25\n",
      "time/training: 321.73075819015503\n",
      "time/total: 7809.520475149155\n",
      "time/evaluation: 0.00020599365234375\n",
      "training/train_loss_mean: 119.30843975906372\n",
      "training/train_loss_std: 8.77541153879623\n",
      "training/action_error: 124.66170501708984\n",
      "================================================================================\n",
      "Iteration 26\n",
      "time/training: 303.11727571487427\n",
      "time/total: 8112.644944429398\n",
      "time/evaluation: 0.00020503997802734375\n",
      "training/train_loss_mean: 119.31801755447388\n",
      "training/train_loss_std: 8.948987389446357\n",
      "training/action_error: 114.48188781738281\n",
      "================================================================================\n",
      "Iteration 27\n",
      "time/training: 308.7909138202667\n",
      "time/total: 8421.442227602005\n",
      "time/evaluation: 0.0002086162567138672\n",
      "training/train_loss_mean: 119.23041421432495\n",
      "training/train_loss_std: 8.82838501550479\n",
      "training/action_error: 120.70442199707031\n",
      "================================================================================\n",
      "Iteration 28\n",
      "time/training: 304.79467511177063\n",
      "time/total: 8726.243446111679\n",
      "time/evaluation: 0.00020551681518554688\n",
      "training/train_loss_mean: 119.27918050384521\n",
      "training/train_loss_std: 8.839942349856384\n",
      "training/action_error: 122.1570053100586\n",
      "================================================================================\n",
      "Iteration 29\n",
      "time/training: 329.06808590888977\n",
      "time/total: 9055.317393302917\n",
      "time/evaluation: 0.00020694732666015625\n",
      "training/train_loss_mean: 119.44124099578858\n",
      "training/train_loss_std: 8.873487267838675\n",
      "training/action_error: 122.59625244140625\n",
      "================================================================================\n",
      "Iteration 30\n",
      "time/training: 312.23013949394226\n",
      "time/total: 9367.55357336998\n",
      "time/evaluation: 0.00022721290588378906\n",
      "training/train_loss_mean: 119.24632582015991\n",
      "training/train_loss_std: 8.82652953496836\n",
      "training/action_error: 116.90630340576172\n",
      "================================================================================\n",
      "Iteration 31\n",
      "time/training: 323.3212537765503\n",
      "time/total: 9690.881288290024\n",
      "time/evaluation: 0.0002143383026123047\n",
      "training/train_loss_mean: 119.25450479736328\n",
      "training/train_loss_std: 8.89994921943089\n",
      "training/action_error: 119.69969177246094\n",
      "================================================================================\n",
      "Iteration 32\n",
      "time/training: 333.7709901332855\n",
      "time/total: 10024.65871834755\n",
      "time/evaluation: 0.00021195411682128906\n",
      "training/train_loss_mean: 119.16211668548584\n",
      "training/train_loss_std: 8.918061953579462\n",
      "training/action_error: 111.93939208984375\n"
     ]
    }
   ],
   "source": [
    "!python experiment.py --env alchemy --dataset chem --model_type dt --max_iters 100 -w True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4c1149b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "{'observations': array([[ 0.,  1., -1., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "       [ 0.,  1.,  1., ...,  0.,  0.,  0.],\n",
      "       ...,\n",
      "       [ 2.,  2.,  2., ...,  0.,  1.,  1.],\n",
      "       [ 2.,  2.,  2., ...,  0.,  1.,  1.],\n",
      "       [ 2.,  2.,  2., ...,  0.,  1.,  1.]], dtype=float32), 'actions': array([ 3,  6,  5, 21, 20, 15, 22, 23, 24, 17, 25, 14,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0, 33, 18, 22, 25, 29, 14, 27,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  3,  1, 14, 27,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0, 15, 38, 31, 29,  1, 14, 27,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13, 19, 16, 25,  1,\n",
      "       14,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 10, 16,\n",
      "       35, 39,  1, 14, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0, 28, 31, 30,  1, 14, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0, 11, 13,  1, 27,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0, 23,  1, 14, 27,  0,  0,  0,  0,  0,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  4, 26,  7,  1, 14, 27,  0,\n",
      "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]), 'rewards': array([ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0., -1.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "       -3., -1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0., -1., -1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        1., -1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0., -1., 15.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0., -1.,  1.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0., -1., -1., 15.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        1., -3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0., -1.,  1., 15.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0., 15., 15., -3.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
      "        0.,  0.,  0.,  0.,  0.]), 'terminals': array([False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False, False, False, False, False, False, False, False,\n",
      "       False, False]), 'chemistry': array([[0., 0., 1., ..., 1., 0., 0.],\n",
      "       [0., 0., 1., ..., 1., 0., 0.],\n",
      "       [0., 0., 1., ..., 1., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 1., ..., 1., 0., 0.],\n",
      "       [0., 0., 1., ..., 1., 0., 0.],\n",
      "       [0., 0., 1., ..., 1., 0., 0.]], dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "\n",
    "with open('data/alchemy-true-v4.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "\n",
    "print(len(data))\n",
    "print(data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e88b4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.craft import Craft\n",
    "from random import Random\n",
    "seed = 2022\n",
    "rng = Random(seed)\n",
    "env = Craft(\"./src/maps/fourobjects.txt\", rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb80a722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "Starting new experiment: craft medium\n",
      "10000 trajectories, 1500000 timesteps found\n",
      "Average return: -148.93, std: 2.89\n",
      "Max return: 9.00, min: -150.00\n",
      "==================================================\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.9.1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Wandb version 0.13.5 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in wandb/run-20221202_004731-2ov5kf9w\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgym-experiment-craft-medium-428429\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://app.wandb.ai/praal/decision-transformer/runs/2ov5kf9w\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb off` to turn off syncing.\n",
      "\n",
      "================================================================================\n",
      "Iteration 1\n",
      "time/training: 477.8435289859772\n",
      "time/total: 479.36161828041077\n",
      "time/evaluation: 0.0002307891845703125\n",
      "training/train_loss_mean: 3.074753875541687\n",
      "training/train_loss_std: 0.34754801689606857\n",
      "training/action_error: 2.8860549926757812\n",
      "================================================================================\n",
      "Iteration 2\n",
      "time/training: 475.9566299915314\n",
      "time/total: 956.1845972537994\n",
      "time/evaluation: 0.0002033710479736328\n",
      "training/train_loss_mean: 3.0039116354227064\n",
      "training/train_loss_std: 0.09590494505074888\n",
      "training/action_error: 2.964897871017456\n",
      "================================================================================\n",
      "Iteration 3\n",
      "time/training: 478.37298798561096\n",
      "time/total: 1434.56387591362\n",
      "time/evaluation: 0.00020241737365722656\n",
      "training/train_loss_mean: 3.0047353626012803\n",
      "training/train_loss_std: 0.09460349187345203\n",
      "training/action_error: 3.0287890434265137\n",
      "================================================================================\n",
      "Iteration 4\n",
      "time/training: 477.46498250961304\n",
      "time/total: 1912.0350382328033\n",
      "time/evaluation: 0.00020170211791992188\n",
      "training/train_loss_mean: 3.005864605951309\n",
      "training/train_loss_std: 0.09643281031804998\n",
      "training/action_error: 3.0239317417144775\n",
      "================================================================================\n",
      "Iteration 5\n",
      "time/training: 478.68986654281616\n",
      "time/total: 2390.730940580368\n",
      "time/evaluation: 0.00021314620971679688\n",
      "training/train_loss_mean: 3.002631597161293\n",
      "training/train_loss_std: 0.09560828154310329\n",
      "training/action_error: 3.2157506942749023\n",
      "================================================================================\n",
      "Iteration 6\n",
      "time/training: 477.9920725822449\n",
      "time/total: 2868.729215860367\n",
      "time/evaluation: 0.0002124309539794922\n",
      "training/train_loss_mean: 3.004475264787674\n",
      "training/train_loss_std: 0.09448862057280327\n",
      "training/action_error: 2.981050968170166\n",
      "================================================================================\n",
      "Iteration 7\n",
      "time/training: 476.62559819221497\n",
      "time/total: 3345.360866546631\n",
      "time/evaluation: 0.00020575523376464844\n",
      "training/train_loss_mean: 3.0034723133802412\n",
      "training/train_loss_std: 0.09581713824082101\n",
      "training/action_error: 3.1122195720672607\n",
      "================================================================================\n",
      "Iteration 8\n",
      "time/training: 476.6755750179291\n",
      "time/total: 3822.0424361228943\n",
      "time/evaluation: 0.0002090930938720703\n",
      "training/train_loss_mean: 3.003845826268196\n",
      "training/train_loss_std: 0.0949865188701319\n",
      "training/action_error: 3.1209676265716553\n",
      "================================================================================\n",
      "Iteration 9\n",
      "time/training: 476.5811893939972\n",
      "time/total: 4298.630084037781\n",
      "time/evaluation: 0.00021076202392578125\n",
      "training/train_loss_mean: 3.0053759399414064\n",
      "training/train_loss_std: 0.09473880007141466\n",
      "training/action_error: 3.0289220809936523\n",
      "================================================================================\n",
      "Iteration 10\n",
      "time/training: 476.0282075405121\n",
      "time/total: 4774.664332151413\n",
      "time/evaluation: 0.0002048015594482422\n",
      "training/train_loss_mean: 3.003592153739929\n",
      "training/train_loss_std: 0.0955168345411585\n",
      "training/action_error: 3.0886287689208984\n",
      "================================================================================\n",
      "Iteration 11\n",
      "time/training: 477.0288646221161\n",
      "time/total: 5251.699449062347\n",
      "time/evaluation: 0.00023674964904785156\n",
      "training/train_loss_mean: 3.0053292257547377\n",
      "training/train_loss_std: 0.09555113776342816\n",
      "training/action_error: 2.927135705947876\n",
      "================================================================================\n",
      "Iteration 12\n",
      "time/training: 476.8926377296448\n",
      "time/total: 5728.598380088806\n",
      "time/evaluation: 0.00020837783813476562\n",
      "training/train_loss_mean: 3.005067161178589\n",
      "training/train_loss_std: 0.09501481225299982\n",
      "training/action_error: 2.994809865951538\n",
      "================================================================================\n",
      "Iteration 13\n",
      "time/training: 478.45342087745667\n",
      "time/total: 6207.057633399963\n",
      "time/evaluation: 0.00020575523376464844\n",
      "training/train_loss_mean: 3.00348060772419\n",
      "training/train_loss_std: 0.09385488566141963\n",
      "training/action_error: 3.107020616531372\n",
      "================================================================================\n",
      "Iteration 14\n",
      "time/training: 477.4178047180176\n",
      "time/total: 6684.481307268143\n",
      "time/evaluation: 0.00021505355834960938\n",
      "training/train_loss_mean: 3.0032098829984664\n",
      "training/train_loss_std: 0.09447744014514983\n",
      "training/action_error: 2.934256076812744\n",
      "================================================================================\n",
      "Iteration 15\n",
      "time/training: 476.7956337928772\n",
      "time/total: 7161.283015012741\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 3.0055374091625215\n",
      "training/train_loss_std: 0.09581721209899324\n",
      "training/action_error: 3.2013423442840576\n",
      "================================================================================\n",
      "Iteration 16\n",
      "time/training: 477.0758385658264\n",
      "time/total: 7638.364888429642\n",
      "time/evaluation: 0.0002086162567138672\n",
      "training/train_loss_mean: 3.006094361948967\n",
      "training/train_loss_std: 0.0953442079045121\n",
      "training/action_error: 2.973597526550293\n",
      "================================================================================\n",
      "Iteration 17\n",
      "time/training: 476.2217528820038\n",
      "time/total: 8114.592880487442\n",
      "time/evaluation: 0.0002040863037109375\n",
      "training/train_loss_mean: 3.0040587742567064\n",
      "training/train_loss_std: 0.09510836408498827\n",
      "training/action_error: 2.877805471420288\n",
      "================================================================================\n",
      "Iteration 18\n",
      "time/training: 475.1243691444397\n",
      "time/total: 8589.723432064056\n",
      "time/evaluation: 0.00020432472229003906\n",
      "training/train_loss_mean: 3.0054093758106233\n",
      "training/train_loss_std: 0.09494474984218042\n",
      "training/action_error: 2.973515272140503\n",
      "================================================================================\n",
      "Iteration 19\n",
      "time/training: 475.57120633125305\n",
      "time/total: 9065.301442623138\n",
      "time/evaluation: 0.0002033710479736328\n",
      "training/train_loss_mean: 3.0060481969833375\n",
      "training/train_loss_std: 0.09480060955989017\n",
      "training/action_error: 2.9495725631713867\n",
      "================================================================================\n",
      "Iteration 20\n",
      "time/training: 476.7553925514221\n",
      "time/total: 9542.062724113464\n",
      "time/evaluation: 0.00020551681518554688\n",
      "training/train_loss_mean: 3.0063068375349045\n",
      "training/train_loss_std: 0.09485354264803625\n",
      "training/action_error: 2.9709153175354004\n",
      "\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 31055\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Program ended successfully.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 _timestamp 1669951593.689226\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                   _runtime 9552.802630901337\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:      training/action_error 2.9709153175354004\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:    training/train_loss_std 0.09485354264803625\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:   training/train_loss_mean 3.0063068375349045\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                 time/total 9542.062724113464\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:              time/training 476.7553925514221\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:                      _step 19\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:            time/evaluation 0.00020551681518554688\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:                                                                                \n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Synced gym-experiment-craft-medium-428429: https://app.wandb.ai/praal/decision-transformer/runs/2ov5kf9w\n"
     ]
    }
   ],
   "source": [
    "!python experiment.py --env craft --dataset medium --model_type dt --max_iters 20 -w True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920af253",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
